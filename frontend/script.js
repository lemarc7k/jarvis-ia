// const API_BASE = "http://localhost:3000"; // ‚ùå SOLO FUNCIONA EN LOCAL
const API_BASE = window.location.hostname.includes("localhost")
  ? "http://localhost:3000"
  : "https://jarvis-ia.onrender.com";

const jarvisCore = document.getElementById("jarvisCore");
const wave = document.getElementById("voice-wave");
const recordBtn = document.getElementById("recordBtn");
const status = document.getElementById("status");
const transcriptionBox = document.getElementById("transcription");
const responseBox = document.getElementById("response");
const manualInput = document.getElementById("manualText");
const sendBtn = document.getElementById("sendBtn");

let mediaRecorder;
let audioChunks = [];

// Animaciones
function glowOn() {
  wave.style.display = "flex";
  jarvisCore.classList.add("glow");
  jarvisCore.style.animation = "none";
}
function glowOff() {
  wave.style.display = "none";
  jarvisCore.classList.remove("glow");
  jarvisCore.style.animation = "float 4s ease-in-out infinite";
  status.textContent = "En espera de su consulta...";
}

// GRABAR + ENVIAR AUDIO
async function startRecording() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    if (!MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) {
      alert("Tu navegador no soporta grabaci√≥n en audio/webm;codecs=opus");
      return;
    }

    mediaRecorder = new MediaRecorder(stream, {
      mimeType: "audio/webm;codecs=opus",
    });

    console.log("üéôÔ∏è Micr√≥fono activo. Grabando...");

    audioChunks = [];

    mediaRecorder.ondataavailable = (e) => {
      if (e.data.size) audioChunks.push(e.data);
    };

    mediaRecorder.onstop = async () => {
      const blob = new Blob(audioChunks, { type: "audio/webm" });
      console.log("üìº Blob generado:", blob);
      console.log("üìº Tama√±o del blob:", blob.size, "bytes");

      const fd = new FormData();
      fd.append("audio", blob, "voice.webm");

      status.textContent = "Procesando consulta...";
      glowOn();

      try {
        console.log("üì° Enviando audio a:", `${API_BASE}/api/voice`);
        console.log("üì§ FormData contiene archivo:", fd.get("audio"));

        const res = await fetch(`${API_BASE}/api/voice`, {
          method: "POST",
          body: fd,
        });

        if (!res.ok) throw new Error("Error en /api/voice");

        const data = await res.json();

        console.log("‚úÖ Transcripci√≥n recibida:", data.transcription);
        console.log("‚úÖ Respuesta IA:", data.response);

        transcriptionBox.textContent = data.transcription;
        responseBox.textContent = data.response;
        await reproducirVoz(data.response);
      } catch (err) {
        console.error(
          "‚ùå Error durante el env√≠o de audio o respuesta IA:",
          err
        );
        responseBox.textContent = "‚ùå Error procesando la voz.";
      }

      status.textContent = "‚úÖ Pulsa para hablar de nuevo";
    };

    mediaRecorder.start();
    status.textContent = "üéôÔ∏è Grabando... pulsa de nuevo para detener";

    // Autom√°tico tras 5s
    setTimeout(() => {
      if (mediaRecorder.state === "recording") {
        console.log("‚è±Ô∏è Tiempo l√≠mite alcanzado. Deteniendo grabaci√≥n.");
        mediaRecorder.stop();
      }
    }, 5000);
  } catch (err) {
    console.error("‚ùå Error accediendo al micr√≥fono:", err);
    status.textContent = "‚ùå Error accediendo al micr√≥fono.";
  }
}

// ENVIAR TEXTO MANUAL
async function enviarTextoManual() {
  const prompt = manualInput.value.trim();
  if (!prompt) return;

  glowOn();
  status.textContent = "Consultando...";

  try {
    console.log("‚å®Ô∏è Enviando prompt manual:", prompt);

    const res = await fetch(`${API_BASE}/api/ia`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ prompt }),
    });

    if (!res.ok) throw new Error("Error en /api/ia");

    const { respuesta } = await res.json();

    console.log("ü§ñ Respuesta IA (manual):", respuesta);

    responseBox.textContent = respuesta;
    transcriptionBox.textContent = prompt;
    await reproducirVoz(respuesta);
  } catch (err) {
    console.error("‚ùå Error en texto manual:", err);
    responseBox.textContent = "‚ùå Error procesando el texto.";
  }
}

// TTS nativo
function reproducirVoz(texto) {
  if (!texto) return;
  const synth = window.speechSynthesis;
  const u = new SpeechSynthesisUtterance(texto);
  u.lang = "es-ES";
  u.rate = 1;
  u.pitch = 0.8;
  glowOn();
  u.onend = glowOff;
  console.log("üîä Reproduciendo respuesta por voz...");
  synth.speak(u);
}

// EVENTOS
recordBtn.addEventListener("click", () => {
  if (mediaRecorder?.state === "recording") {
    console.log("‚èπÔ∏è Deteniendo grabaci√≥n por clic");
    mediaRecorder.stop();
    recordBtn.disabled = true;
    status.textContent = "‚èπÔ∏è Procesando...";
    return;
  }
  new Audio("/assets/bootup.wav").play();
  startRecording();
  recordBtn.disabled = false;
});

sendBtn.addEventListener("click", enviarTextoManual);
